{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T12:09:31.938120Z",
     "start_time": "2025-02-24T12:09:31.935317Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T12:09:32.585400Z",
     "start_time": "2025-02-24T12:09:32.379741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Coefficient  Std Error  t-Statistic\n",
      "Intercept     5.263354   0.207372    25.381238\n",
      "exp           0.006818   0.001121     6.083924\n",
      "wks           0.010138   0.003686     2.750502\n",
      "bluecol      -0.175745   0.034588    -5.081148\n",
      "ind           0.063580   0.026127     2.433442\n",
      "south        -0.054965   0.026583    -2.067643\n",
      "smsa          0.170499   0.026351     6.470270\n",
      "married       0.134801   0.048685     2.768811\n",
      "gender       -0.300047   0.055936    -5.364162\n",
      "union         0.118502   0.029874     3.966651\n",
      "edu           0.051728   0.005687     9.096532\n",
      "colour       -0.157205   0.046084    -3.411297\n",
      "R-squared = 0.5215\n",
      "Estimate of variance σ2_α = 0.0758\n"
     ]
    }
   ],
   "source": [
    "y_var = \"lwage\"\n",
    "x_vars = [\"exp\", \"wks\", \"bluecol\", \"ind\", \"south\", \"smsa\", \"married\", \"gender\", \"union\", \"edu\", \"colour\"]\n",
    "\n",
    "def between_regression(y, X , N=595, T=7):\n",
    "    I_T = np.ones((T, 1))\n",
    "    I_N = np.eye(N)\n",
    "    D = np.kron(I_N, I_T)\n",
    "    P_D = D @ np.linalg.inv(D.T @ D) @ D.T\n",
    "    \n",
    "    # Averaged y and X per individual\n",
    "    y_bar = (P_D @ y).reshape(N, T).mean(axis=1, keepdims=True)\n",
    "    X_bar = (P_D @ X).reshape(N, T, X.shape[1]).mean(axis=1)  # Compute mean for each variable\n",
    "    \n",
    "    XtX_inv = np.linalg.inv(X_bar.T @ X_bar)\n",
    "    beta_B = XtX_inv @ (X_bar.T @ y_bar)\n",
    "    \n",
    "    # Compute residuals correctly per individual\n",
    "    a_i = y_bar - X_bar @ beta_B\n",
    "    sigma2_alpha = np.sum(a_i**2) / (N - X.shape[1])\n",
    "    \n",
    "    # Compute standard errors\n",
    "    s2_B = sigma2_alpha\n",
    "    Sigma_B = XtX_inv\n",
    "    se_B = np.sqrt(s2_B * np.diag(Sigma_B))\n",
    "\n",
    "    # Compute t-values\n",
    "    t_values = beta_B.flatten() / se_B\n",
    "    \n",
    "    # Compute R squared\n",
    "    ss_total = np.sum((y_bar - np.mean(y_bar)) ** 2)\n",
    "    ss_residual = np.sum(a_i**2)\n",
    "    R2 = 1 - (ss_residual / ss_total)\n",
    "    \n",
    "    return beta_B, t_values, se_B, R2, sigma2_alpha\n",
    "\n",
    "# Load data\n",
    "file_path = \"data_assignment1.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "data = data.iloc[:, 2:]  # Ignore first two columns\n",
    "\n",
    "# Prepare y and X\n",
    "y = data[y_var].to_numpy().reshape(-1, 1)  # Ensure y is (NT, 1)\n",
    "X = np.column_stack((np.ones(len(y)), data[x_vars].to_numpy()))  # Add constant for intercept\n",
    "\n",
    "# Run between regression\n",
    "beta_B, t_values, se_B, R2, sigma2_alpha = between_regression(y, X)\n",
    "    \n",
    "# Summary Table\n",
    "results = pd.DataFrame({\n",
    "    \"Coefficient\": beta_B.flatten(),\n",
    "    \"Std Error\": se_B,\n",
    "    \"t-Statistic\": t_values\n",
    "}, index=[\"Intercept\"] + x_vars)\n",
    "\n",
    "print(results)\n",
    "print(f\"R-squared = {R2:.4f}\")\n",
    "print(f\"Estimate of variance σ2_α = {sigma2_alpha:.4f}\")\n",
    "    \n",
    "latex_output = results.style.to_latex()\n",
    "    \n",
    "# Output Latex table\n",
    "with open(\"between_estimation_results.tex\", \"w\") as f:\n",
    "    f.write(\"\\\\begin{table}[h]\\\\centering\\n\")\n",
    "    f.write(latex_output + \"\\n\")\n",
    "    f.write(\"\\\\caption{Between Estimation Results}\\n\")\n",
    "    f.write(\"\\\\label{tab:between_estimation}\\n\")\n",
    "    f.write(\"\\\\end{table}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T12:09:33.085886Z",
     "start_time": "2025-02-24T12:09:32.849726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Coefficient  Std Error  t-Statistic\n",
      "exp         0.096577   0.001191    81.099181\n",
      "wks         0.001142   0.000603     1.893728\n",
      "bluecol    -0.024864   0.013888    -1.790356\n",
      "ind         0.020757   0.015570     1.333145\n",
      "south      -0.003198   0.034576    -0.092491\n",
      "smsa       -0.043727   0.019584    -2.232743\n",
      "married    -0.030260   0.019137    -1.581241\n",
      "union       0.034158   0.015042     2.270828\n",
      "R-squared = 0.6525\n",
      "Estimated between regression variance = 0.0235\n"
     ]
    }
   ],
   "source": [
    "y_var = \"lwage\"\n",
    "x_vars = [\"exp\", \"wks\", \"bluecol\", \"ind\", \"south\", \"smsa\", \"married\", \"union\"]\n",
    "\n",
    "###########################################################\n",
    "\n",
    "\n",
    "def within_regression(y, X , N=595, T=7):\n",
    "    I_T = np.ones((T, 1)) \n",
    "    I_N = np.eye(N) \n",
    "    I_NT = np.eye(N*T)\n",
    "    D = np.kron(I_N, I_T)  \n",
    "    M_D = I_NT - D @ np.linalg.inv(D.T @ D) @ D.T\n",
    "    \n",
    "    # Differenced y and X per individual\n",
    "    y_tilde = M_D @ y\n",
    "    X_tilde = M_D @ X\n",
    "    \n",
    "    XtX_inv = np.linalg.inv(X_tilde.T @ X_tilde)\n",
    "    beta_W = XtX_inv @ (X_tilde.T @ y_tilde)\n",
    "    \n",
    "    # Compute residuals\n",
    "    u_i = y_tilde - X_tilde @ beta_W\n",
    "    sigma2_eta = (1 / (N*(T-1)  - X.shape[1])) * np.sum(u_i**2)\n",
    "    \n",
    "    # Compute standard errors\n",
    "    s2_W = sigma2_eta\n",
    "    Sigma_W = XtX_inv\n",
    "    se_W = np.sqrt(s2_W * np.diag(Sigma_W))\n",
    "\n",
    "    # Compute t-values\n",
    "    t_values = beta_W.flatten() / se_W\n",
    "    \n",
    "    #Compute R squared\n",
    "    ss_total = np.sum((y_tilde - np.mean(y_tilde)) ** 2)\n",
    "    ss_residual = np.sum((y_tilde - X_tilde @ beta_W) ** 2)\n",
    "    R2 = 1 - (ss_residual / ss_total)\n",
    "\n",
    "    return beta_W, t_values, se_W, R2, sigma2_eta, Sigma_W\n",
    "\n",
    "y = data[y_var].to_numpy()\n",
    "X = data[x_vars].to_numpy()\n",
    "\n",
    "beta_W, t_values, se_W, R2, sigma2_eta, Sigma_W = within_regression(y,X)\n",
    "    \n",
    "# Summary Table\n",
    "results = pd.DataFrame({\n",
    "\"Coefficient\": beta_W,\n",
    "\"Std Error\": se_W,\n",
    "\"t-Statistic\": t_values\n",
    "}, index=x_vars)\n",
    "\n",
    "print(results)\n",
    "print(f\"R-squared = {R2:.4f}\")\n",
    "print(f\"Estimated between regression variance = {sigma2_eta:.4f}\")\n",
    "    \n",
    "latex_output = results.style.to_latex()\n",
    "    \n",
    "# Output Latex table\n",
    "with open(\"within_estimation_results.tex\", \"w\") as f:\n",
    "    f.write(\"\\\\begin{table}[h]\\\\centering\\n\")\n",
    "    f.write(latex_output + \"\\n\")\n",
    "    f.write(\"\\\\caption{Within Estimation Results}\\n\")\n",
    "    f.write(\"\\\\label{tab:within_estimation}\\n\")\n",
    "    f.write(\"\\\\end{table}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T12:09:33.220605Z",
     "start_time": "2025-02-24T12:09:33.198168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.023476664933713122)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma2_eta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T12:09:34.281200Z",
     "start_time": "2025-02-24T12:09:34.277994Z"
    }
   },
   "outputs": [],
   "source": [
    "data.insert(0, \"intercept\", 1)\n",
    "data['individual'] = (data.index // 7) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T12:09:35.615419Z",
     "start_time": "2025-02-24T12:09:35.393298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Coefficient  Std Error  t-Statistic\n",
      "intercept     4.427204   0.099498    44.495552\n",
      "exp           0.049531   0.001064    46.530142\n",
      "wks           0.001621   0.000780     2.078656\n",
      "bluecol      -0.055488   0.016877    -3.287758\n",
      "ind           0.007128   0.017587     0.405291\n",
      "south        -0.012423   0.027399    -0.453419\n",
      "smsa         -0.024358   0.020439    -1.191742\n",
      "married      -0.073246   0.023331    -3.139445\n",
      "gender       -0.329828   0.053454    -6.170263\n",
      "union         0.067483   0.017364     3.886434\n",
      "edu           0.102985   0.005990    17.192411\n",
      "colour       -0.217087   0.060703    -3.576238\n",
      "R-squared = 0.3739\n",
      "Estimated theta = 0.2059\n"
     ]
    }
   ],
   "source": [
    "y_var = \"lwage\"\n",
    "x_vars = [\"intercept\", \"exp\", \"wks\", \"bluecol\", \"ind\", \"south\", \"smsa\", \"married\", \"gender\", \"union\", \"edu\", \"colour\"]\n",
    "\n",
    "# calculate the mean of each individual\n",
    "df_mean = data.groupby(\"individual\").mean().reset_index()\n",
    "\n",
    "N=595\n",
    "T=7\n",
    "I_T = np.ones((T, 1))\n",
    "\n",
    "# Calculate theta_hat:\n",
    "theta2_hat = sigma2_eta / (T * sigma2_alpha + sigma2_eta)\n",
    "theta_hat = np.sqrt(theta2_hat)\n",
    "\n",
    "# Change df_mean to numpy array\n",
    "df_mean_X = df_mean[x_vars].to_numpy()\n",
    "df_mean_y = df_mean[y_var].to_numpy()\n",
    "\n",
    "# Calculate the FGLS estimator\n",
    "first_sum = 0\n",
    "second_sum = 0\n",
    "\n",
    "y_star_list = []\n",
    "X_star_list = []\n",
    "\n",
    "for i in range(N):\n",
    "    individual_X = data[data[\"individual\"] == i+1][x_vars]\n",
    "    individual_X = individual_X.to_numpy()\n",
    "    Xi_star = 1/sigma2_eta * (individual_X - (1 - theta_hat) * df_mean_X[i])\n",
    "    first_sum += Xi_star.T @ Xi_star\n",
    "\n",
    "    individual_y = data[data[\"individual\"] == i+1][y_var].to_numpy()\n",
    "    yi_star = 1/sigma2_eta * (individual_y - (1 - theta_hat) * df_mean_y[i])\n",
    "    second_sum += Xi_star.T @ yi_star\n",
    "\n",
    "    y_star_list.append(yi_star)\n",
    "    X_star_list.append(Xi_star)\n",
    "\n",
    "# Calculate the FGLS estimator\n",
    "beta_FGLS = np.linalg.inv(first_sum) @ second_sum\n",
    "y_star = np.concatenate(y_star_list)\n",
    "X_star = np.concatenate(X_star_list)\n",
    "\n",
    "residuals = y_star - X_star @ beta_FGLS  # Residuals from FGLS\n",
    "\n",
    "# Compute estimated residual variance\n",
    "N, k = X_star.shape  # NT = number of observations, k = number of parameters\n",
    "sigma2_hat = (residuals.T @ residuals) / (N - k)\n",
    "\n",
    "# Compute standard errors\n",
    "Sigma_FGLS = np.linalg.inv(first_sum)\n",
    "se_FGLS = np.sqrt(np.diag(sigma2_hat * Sigma_FGLS))\n",
    "\n",
    "# Compute t-values\n",
    "t_values = beta_FGLS.flatten() / se_FGLS\n",
    "\n",
    "# Compute R squared\n",
    "\n",
    "R2 = r2_score(y_star, X_star @ beta_FGLS)\n",
    "\n",
    "# Summary Table\n",
    "results = pd.DataFrame({\n",
    "\"Coefficient\": beta_FGLS,\n",
    "\"Std Error\": se_FGLS,\n",
    "\"t-Statistic\": t_values\n",
    "}, index=x_vars)\n",
    "\n",
    "print(results)\n",
    "print(f\"R-squared = {R2:.4f}\")\n",
    "print(f\"Estimated theta = {np.sqrt(theta2_hat):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T12:10:34.067035Z",
     "start_time": "2025-02-24T12:10:34.057007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hausman Test Statistic: 36.9639\n",
      "p-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# We can calculate Hausman statistic only using variables that are not constant over time\n",
    "x_var_not_constant = [\"exp\", \"wks\", \"bluecol\", \"ind\", \"south\", \"smsa\", \"married\", \"union\"]\n",
    "\n",
    "# Use variable names as index for FGLS results\n",
    "beta_FGLS_pd = pd.Series(beta_FGLS.flatten(), index=[\"intercept\", \"exp\", \"wks\", \"bluecol\", \"ind\", \"south\", \"smsa\", \"married\", \"gender\", \"union\", \"edu\", \"colour\"])\n",
    "Sigma_FGLS = pd.DataFrame(Sigma_FGLS, index=beta_FGLS_pd.index, columns=beta_FGLS_pd.index)\n",
    "\n",
    "# For FGLS results keep only values that are calculated for variables that are not constant over time\n",
    "beta_FGLS_matched = beta_FGLS_pd.loc[x_var_not_constant]\n",
    "Sigma_FGLS_matched = Sigma_FGLS.loc[x_var_not_constant, x_var_not_constant]\n",
    "\n",
    "# Compute Hausman test statistic\n",
    "beta_diff = beta_FGLS_matched - beta_W\n",
    "var_diff = Sigma_W - Sigma_FGLS_matched\n",
    "statistic = beta_diff.T @ np.linalg.inv(var_diff) @ beta_diff\n",
    "p_value = 1 - stats.chi2.cdf(statistic, len(x_var_not_constant))\n",
    "\n",
    "print(f\"Hausman Test Statistic: {statistic:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Variable  Coefficient  Standard Error  t-Statistic\n",
      "0      wks     0.000949        0.000557     1.702706\n",
      "1  bluecol    -0.022131        0.012804    -1.728487\n",
      "2      ind     0.022358        0.014346     1.558453\n",
      "3    south     0.002289        0.031853     0.071872\n",
      "4     smsa    -0.043182        0.018050    -2.392331\n",
      "5  married    -0.028990        0.017627    -1.644654\n",
      "6    union     0.030675        0.013864     2.212498\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"data_assignment1.csv\")\n",
    "\n",
    "# Define dependent and independent variables \n",
    "y_var = \"lwage\"\n",
    "x_vars_corrected = [\"wks\", \"bluecol\", \"ind\", \"south\", \"smsa\", \"married\", \"union\"]  \n",
    "\n",
    "# Add ID and Year columns based on dataset structure\n",
    "df[\"ID\"] = np.repeat(np.arange(1, 596), 7)  \n",
    "df[\"Year\"] = np.tile(np.arange(1976, 1983), 595) \n",
    "\n",
    "# Compute means for demeaning\n",
    "y_mean_i = df.groupby(\"ID\")[y_var].transform(\"mean\")  # Individual mean\n",
    "y_mean_t = df.groupby(\"Year\")[y_var].transform(\"mean\")  # Time mean\n",
    "y_mean_overall = df[y_var].mean()  # Overall mean\n",
    "\n",
    "# Compute transformed y\n",
    "df[\"y_twfe\"] = df[y_var] - y_mean_i - y_mean_t + y_mean_overall\n",
    "\n",
    "# Compute transformed X variables (demeaning)\n",
    "for var in x_vars_corrected:\n",
    "    x_mean_i = df.groupby(\"ID\")[var].transform(\"mean\")  # Individual mean\n",
    "    x_mean_t = df.groupby(\"Year\")[var].transform(\"mean\")  # Time mean\n",
    "    x_mean_overall = df[var].mean()  # Overall mean\n",
    "    df[f\"x_twfe_{var}\"] = df[var] - x_mean_i - x_mean_t + x_mean_overall\n",
    "\n",
    "# Prepare X and Y matrices\n",
    "X_twfe = df[[f\"x_twfe_{var}\" for var in x_vars_corrected]].to_numpy()  # Convert to NumPy array\n",
    "y_twfe = df[\"y_twfe\"].to_numpy().reshape(-1, 1)  # Convert to column vector\n",
    "\n",
    "# Compute OLS manually using matrix algebra\n",
    "beta_hat = np.linalg.inv(X_twfe.T @ X_twfe) @ (X_twfe.T @ y_twfe)  # OLS estimate\n",
    "\n",
    "# Compute residuals\n",
    "residuals = y_twfe - X_twfe @ beta_hat\n",
    "sigma2_eta = (residuals.T @ residuals) / (len(y_twfe) - len(x_vars_corrected))  # Variance estimate\n",
    "\n",
    "# Compute standard errors\n",
    "var_beta_hat = sigma2_eta * np.linalg.inv(X_twfe.T @ X_twfe)\n",
    "se_beta_hat = np.sqrt(np.diag(var_beta_hat))\n",
    "\n",
    "# Compute t-values\n",
    "t_values = beta_hat.flatten() / se_beta_hat.flatten()\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame({\n",
    "    \"Variable\": x_vars_corrected,\n",
    "    \"Coefficient\": beta_hat.flatten(),\n",
    "    \"Standard Error\": se_beta_hat,\n",
    "    \"t-Statistic\": t_values\n",
    "})\n",
    "\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
